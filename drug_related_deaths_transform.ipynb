{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading localauthoritiesregistrations201517.xlsx which has size 1250896 bytes\n",
      "Table names: ['Poisoning persons', 'Poisoning males', 'Poisoning females', 'Misuse persons', 'Misuse males', 'Misuse females']\n",
      "TIMEUNIT=''\n",
      "Poisoning persons - databaked\n",
      "TIMEUNIT=''\n",
      "Poisoning males - databaked\n",
      "TIMEUNIT=''\n",
      "Poisoning females - databaked\n",
      "TIMEUNIT=''\n",
      "Misuse persons - databaked\n",
      "TIMEUNIT=''\n",
      "Misuse males - databaked\n",
      "TIMEUNIT=''\n",
      "Misuse females - databaked\n",
      "Extracting data structured as v4.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from databaker.framework import *\n",
    "from databakerUtils.writers import v4Writer\n",
    "import requests\n",
    "\n",
    "inputFile = 'localauthoritiesregistrations201517.xlsx'\n",
    "outputFile = 'v4_drug-related-deaths.csv'\n",
    "\n",
    "tabsWeWant = ['Poisoning persons', 'Poisoning males', 'Poisoning females', \n",
    "              'Misuse persons', 'Misuse males', 'Misuse females']\n",
    "\n",
    "tabs = loadxlstabs(inputFile, tabsWeWant)\n",
    "\n",
    "conversionsegments = []\n",
    "\n",
    "for tab in tabs:\n",
    "    \n",
    "    assert tab.excel_ref('A3').value == 'Area Code'\n",
    "    \n",
    "    key = tab.excel_ref('A').filter(contains_string('Age-standardised mortality')).expand(DOWN)\n",
    "    \n",
    "    geogCodes = tab.excel_ref('A6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    geogCodes -= key\n",
    "    geogLabels = tab.excel_ref('B6:D6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    \n",
    "    time = tab.excel_ref('E3').expand(RIGHT).is_not_blank().is_not_whitespace()\n",
    "    \n",
    "    mortality = tab.excel_ref('E4').expand(RIGHT).is_not_blank().is_not_whitespace()\n",
    "    \n",
    "    sex = tab.name.split()[1]\n",
    "    \n",
    "    typeOfDeath = tab.name.split()[0]\n",
    "    \n",
    "    obs = geogCodes.waffle(mortality)\n",
    "    \n",
    "    dimensions = [\n",
    "                HDim(time, TIME, CLOSEST, LEFT),\n",
    "                HDim(geogCodes, GEOG, DIRECTLY, LEFT),\n",
    "                HDim(geogLabels, 'geogLabels', DIRECTLY, LEFT),\n",
    "                HDim(mortality, 'mortality', DIRECTLY, ABOVE),\n",
    "                HDimConst('sex', sex),\n",
    "                HDimConst('typeOfDeath', typeOfDeath)\n",
    "                ]\n",
    "\n",
    "    conversionsegment = ConversionSegment(tab, dimensions, obs).topandas()\n",
    "    conversionsegments.append(conversionsegment)\n",
    "    \n",
    "    print(tab.name,'- databaked')\n",
    "\n",
    "data = pd.concat(conversionsegments)   \n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "#combing CV's into correct place\n",
    "#concat it twice because the CV's are the same for the deaths and the rates\n",
    "lowerCV = data[data['mortality'] == 'Lower Confidence Limit']\n",
    "lowerCV = pd.concat([lowerCV, lowerCV])\n",
    "lowerCV = lowerCV.sort_index()\n",
    "upperCV = data[data['mortality'] == 'Upper Confidence Limit']\n",
    "upperCV = pd.concat([upperCV, upperCV])\n",
    "upperCV = upperCV.sort_index()\n",
    "\n",
    "#dropping CV's from mortality column\n",
    "data = data[data['mortality'] != 'Lower Confidence Limit']\n",
    "data = data[data['mortality'] != 'Upper Confidence Limit']\n",
    "\n",
    "df = v4Writer(outputFile, data, asFrame=True) \n",
    "df = df.reset_index(drop = True)  \n",
    "lowerCV = lowerCV.reset_index(drop = True)\n",
    "upperCV = upperCV.reset_index(drop = True)\n",
    "\n",
    "df['Lower Confidence Limit'] = lowerCV['OBS']\n",
    "df['Upper Confidence Limit'] = upperCV['OBS']\n",
    "\n",
    "'''Functions'''\n",
    "\n",
    "def sexLabels(value):\n",
    "    lookup = {\n",
    "            'persons':'All',\n",
    "            'males':'Male',\n",
    "            'females':'Female'\n",
    "            }\n",
    "    return lookup[value]\n",
    "\n",
    "url = 'https://api.beta.ons.gov.uk/v1/code-lists/admin-geography/editions/one-off/codes'\n",
    "r = requests.get(url)\n",
    "wholeDict = r.json()\n",
    "adminDict = {}\n",
    "for item in wholeDict['items']:\n",
    "    adminDict.update({item['id']:item['label']})\n",
    "    \n",
    "def adminLabels(value):\n",
    "    return adminDict[value]\n",
    "\n",
    "'''Post Processing'''\n",
    "\n",
    "df['Time_codelist'] = df['Time']\n",
    "\n",
    "df['Geography'] = df['Geography_codelist'].apply(adminLabels)\n",
    "df = df.drop(['geogLabels', 'geogLabels_codelist'], axis = 1)\n",
    "\n",
    "df['mortality_codelist'] = df['mortality'].apply(lambda x:x.lower())\n",
    "\n",
    "df['sex'] = df['sex'].apply(sexLabels)\n",
    "df['sex_codelist'] = df['sex'].apply(lambda x:x.lower())\n",
    "\n",
    "df['typeOfDeath_codelist'] = df['typeOfDeath'].apply(lambda x:x.lower())\n",
    "\n",
    "df = df[['V4_0', 'Data_Marking', 'Lower Confidence Limit', 'Upper Confidence Limit', \n",
    "         'Time_codelist', 'Time', 'Geography_codelist', 'Geography', \n",
    "         'mortality_codelist', 'mortality', 'sex_codelist', 'sex', \n",
    "         'typeOfDeath_codelist', 'typeOfDeath', ]]\n",
    "\n",
    "renameCols = {\n",
    "            'V4_0':'V4_3',\n",
    "            'Time_codelist':'two-year-intervals',\n",
    "            'Time':'time',\n",
    "            'Geography_codelist':'admin-geography',\n",
    "            'Geography':'geography',\n",
    "            'mortality_codelist':'drug-deaths-mortality',\n",
    "            'sex_codelist':'ashe-sex',\n",
    "            'typeOfDeath_codelist':'drug-deaths-type-of-death',\n",
    "            'typeOfDeath':'typeofdeath'\n",
    "            }\n",
    "\n",
    "df = df.rename(columns = renameCols)\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "'''Removing data for codes starting E11 or E13 - they have no data but some datamarkings..'''\n",
    "\n",
    "codesWithNoData = []\n",
    "for code in df['admin-geography'].unique():\n",
    "    if code.startswith('E11') or code.startswith('E13'):\n",
    "        codesWithNoData.append(code)\n",
    "\n",
    "codeList = list(df['admin-geography'])\n",
    "indexOfCodesWithNoData = []\n",
    "for index, code in enumerate(codeList):\n",
    "    if code in codesWithNoData:\n",
    "        indexOfCodesWithNoData.append(index)\n",
    "    \n",
    "df = df.drop(indexOfCodesWithNoData)\n",
    "\n",
    "df.to_csv(outputFile, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
